{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YaSpeller\n",
    "**Проверка орфографии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyaspeller import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['Компьютер']\n"
     ]
    }
   ],
   "source": [
    "check_wrong = Word('Кампьютер')\n",
    "print(check_wrong.correct)\n",
    "print(check_wrong.variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "check_correct = Word('Стол')\n",
    "print(check_correct.correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YaDictionary\n",
    "**Поиск синонимов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import config\n",
    "sys.path.append('portYaDict.py')\n",
    "from portYaDict import YandexDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_syn(word):\n",
    "    \n",
    "    # Получаем ответ API на запрос по слову\n",
    "    dictionary = YandexDictionary(config.API_DICT_KEY)\n",
    "    output = dictionary.lookup(word, 'ru', 'ru')\n",
    "    \n",
    "    # Фильтруем (очищаем) данные\n",
    "    russian_letters = set(\"ёйцукенгшщзхъфывапролджэячсмитьбю \")\n",
    "    russian_text = \"\"\n",
    "    for letter in output:\n",
    "        if letter in russian_letters:\n",
    "            russian_text += letter    \n",
    "        else:\n",
    "            russian_text += \",\"\n",
    "    \n",
    "    # Массив синонимов, возвращаем первые 5\n",
    "    synonymus = []\n",
    "    synonymus = list(filter(lambda x: len(x.split(\" \")) == 1 and len(x) > 0, list(russian_text.split(','))))\n",
    "    \n",
    "    return synonymus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['город', 'сити', 'мегаполис', 'г', 'град']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_syn(\"город\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With difflib\n",
    "**Построение векторов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_diff(text1, text2):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    normalized1 = text1.lower()\n",
    "    normalized2 = text2.lower()\n",
    "    matcher = difflib.SequenceMatcher(None, normalized1, normalized2)\n",
    "    \n",
    "    work_time = round(time.time() - start_time)\n",
    "    print(\"Work time: {0}\".format(work_time))\n",
    "    return matcher.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work time: 0\n",
      "0.6933333333333334\n"
     ]
    }
   ],
   "source": [
    "sim_diff = similarity_diff(\"Мясо гигантских тараканов станет вкусной и недорогой альтернативой говядине\",\n",
    "                      \"Гигантское мясо тараканов станет говядине недорогой и вкусной альтернативой\")\n",
    "print(sim_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With sklearn\n",
    "**Тоже построение векторов (только лучше) + косинусное расстояние**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_sklearn(text1, text2):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    vect = TfidfVectorizer(min_df=1)\n",
    "    tfidf = vect.fit_transform([text1, text2])\n",
    "\n",
    "    work_time = round(time.time() - start_time)\n",
    "    print(\"Work time: {0}\".format(work_time))\n",
    "    return(tfidf * tfidf.T).A[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work time: 0\n",
      "0.7799154245579976\n"
     ]
    }
   ],
   "source": [
    "sim_sklearn = similarity_sklearn(\"Мясо гигантских тараканов станет вкусной и недорогой альтернативой говядине\",\n",
    "                                 \"Гигантское мясо тараканов станет говядине недорогой и вкусной альтернативой\")\n",
    "print(sim_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text clustering\n",
    "**Сравнение векторов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " хлеб\n",
      " изделие\n",
      " без\n",
      " хлебобулочное\n",
      " начинки\n",
      " старейших\n",
      " продуктов\n",
      " один\n",
      " неолите\n",
      " приготавливаемых\n",
      "Cluster 1:\n",
      " вода\n",
      " для\n",
      " является\n",
      " сильнополярным\n",
      " хорошим\n",
      " растворителем\n",
      " основном\n",
      " пресная\n",
      " же\n",
      " находится\n",
      "\n",
      "\n",
      "Prediction\n",
      "[1]\n",
      "[0 1 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "documents = [\"Хлеб — хлебобулочное изделие без начинки\",\n",
    "             \"Для приготовления хлеба употребляют пшеничную и ржаную муку, реже — кукурузную, ячменную и другие\",\n",
    "             \"Хлеб можно есть отдельно, однако нередко его едят со сливочным, арахисовым или подсолнечным маслом\",\n",
    "             \"Хлеб — один из старейших приготавливаемых продуктов, появившийся ещё в неолите\",\n",
    "             \"Вода является хорошим сильнополярным растворителем.\",\n",
    "             \"Исключительно важна роль воды в глобальном кругообороте вещества и энергии\",\n",
    "             \"Это солёная вода, непригодная для сельского хозяйства и питья\",\n",
    "             \"Пресная же вода находится в основном в ледниках\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"Люблю пить воду\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"Ем хлеб с утра и вечером с маслом\"])\n",
    "prediction = model.predict(X)\n",
    "print(prediction)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
